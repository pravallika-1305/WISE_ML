{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_MNIST.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJkYiyS6PjNvCVmdVjsrIy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pravallika-1305/WISE_ML/blob/main/CNN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8hocCPDjiZY",
        "outputId": "93a1c1a7-3813-4385-99b7-7f2155d5b4f7"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "# loading the dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhfh0kdakQs7",
        "outputId": "c873d7fe-dbbe-4ed3-f54e-0c9d554739aa"
      },
      "source": [
        "print(\"X_train shape\", X_train.shape)\n",
        "print(\"y_train shape\", y_train.shape)\n",
        "print(\"X_test shape\", X_test.shape)\n",
        "print(\"y_test shape\", y_test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape (60000, 28, 28)\n",
            "y_train shape (60000,)\n",
            "X_test shape (10000, 28, 28)\n",
            "y_test shape (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOoYVM3blR0L"
      },
      "source": [
        "## **Fully Connected Neural Network**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqVZes6Ukjqb"
      },
      "source": [
        "## Procedure\n",
        "\n",
        "1.   Flatten the input image dimensions to 1D (width pixels x height pixels)\n",
        "2.   Normalize the image pixel values (divide by 255)\n",
        "3.   One-Hot Encode the categorical column\n",
        "4.   Build a model architecture (Sequential) with Dense layers\n",
        "5.   Train the model and make predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1NHtLj4lf4n"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88gvRERiljck"
      },
      "source": [
        "# Flattening the images from the 28x28 pixels to 1D 784 pixels\n",
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u5e-sjilwQU"
      },
      "source": [
        "# normalizing the data to help with the training\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQOKylH_mhSn",
        "outputId": "fb8ebc69-381d-460f-945c-038b21212c57"
      },
      "source": [
        "# one-hot encoding using keras' numpy-related utilities\n",
        "n_classes = 10\n",
        "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
        "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
        "print(\"Shape after one-hot encoding: \", Y_train.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape before one-hot encoding:  (60000,)\n",
            "Shape after one-hot encoding:  (60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k51BVw5pmpM5"
      },
      "source": [
        "# building a linear stack of layers with the sequential model\n",
        "model = Sequential()\n",
        "# hidden layer\n",
        "model.add(Dense(100, input_shape=(784,), activation='relu'))\n",
        "# output layer\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNegPkcVmshH",
        "outputId": "ea16e412-90d9-4ea6-a694-bed0bed8bbf3"
      },
      "source": [
        "# looking at the model summary\n",
        "model.summary()\n",
        "# compiling the sequential model\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "# training the model for 10 epochs\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.6377 - accuracy: 0.8208 - val_loss: 0.2148 - val_accuracy: 0.9368\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.1939 - accuracy: 0.9451 - val_loss: 0.1503 - val_accuracy: 0.9563\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.1386 - accuracy: 0.9604 - val_loss: 0.1193 - val_accuracy: 0.9632\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.1052 - accuracy: 0.9694 - val_loss: 0.1016 - val_accuracy: 0.9691\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0831 - accuracy: 0.9770 - val_loss: 0.0896 - val_accuracy: 0.9719\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0697 - accuracy: 0.9796 - val_loss: 0.0879 - val_accuracy: 0.9729\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0598 - accuracy: 0.9828 - val_loss: 0.0828 - val_accuracy: 0.9743\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0521 - accuracy: 0.9844 - val_loss: 0.0732 - val_accuracy: 0.9775\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0447 - accuracy: 0.9871 - val_loss: 0.0775 - val_accuracy: 0.9766\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.0368 - accuracy: 0.9900 - val_loss: 0.0714 - val_accuracy: 0.9779\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb0f6aa9e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcpnrI92nHL3"
      },
      "source": [
        "## **CNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rROkJuBEnKKj"
      },
      "source": [
        "# keras imports for the dataset and building our neural network\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmafM4axnQxQ"
      },
      "source": [
        "# to calculate accuracy\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60pC-cf0nWAH"
      },
      "source": [
        "# loading the dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKh5f0-TnaQ3"
      },
      "source": [
        "# building the input vector from the 28x28 pixels\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu8BEtvUngNK"
      },
      "source": [
        "# normalizing the data to help with the training\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAKEk4Y5nmLb",
        "outputId": "8195d470-529e-4b90-a88b-f9e690488709"
      },
      "source": [
        "# one-hot encoding using keras' numpy-related utilities\n",
        "n_classes = 10\n",
        "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
        "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
        "print(\"Shape after one-hot encoding: \", Y_train.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape before one-hot encoding:  (60000,)\n",
            "Shape after one-hot encoding:  (60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTWemJranrAX"
      },
      "source": [
        "# building a linear stack of layers with the sequential model\n",
        "model = Sequential()\n",
        "# convolutional layer\n",
        "model.add(Conv2D(25, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
        "model.add(MaxPool2D(pool_size=(1,1)))\n",
        "# flatten output of conv\n",
        "model.add(Flatten())\n",
        "# hidden layer\n",
        "model.add(Dense(100, activation='relu'))\n",
        "# output layer\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq_V8p--nvu-"
      },
      "source": [
        "# compiling the sequential model\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioVVG1OJn0jw",
        "outputId": "cff8e9da-24a7-4c10-ed10-12344cd434b3"
      },
      "source": [
        "# training the model for 10 epochs\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 38s 80ms/step - loss: 0.3737 - accuracy: 0.8900 - val_loss: 0.0803 - val_accuracy: 0.9750\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 38s 81ms/step - loss: 0.0620 - accuracy: 0.9818 - val_loss: 0.0640 - val_accuracy: 0.9788\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 38s 80ms/step - loss: 0.0351 - accuracy: 0.9898 - val_loss: 0.0517 - val_accuracy: 0.9822\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 38s 80ms/step - loss: 0.0223 - accuracy: 0.9931 - val_loss: 0.0611 - val_accuracy: 0.9810\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 38s 81ms/step - loss: 0.0134 - accuracy: 0.9964 - val_loss: 0.0591 - val_accuracy: 0.9829\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 38s 80ms/step - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.0573 - val_accuracy: 0.9821\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 38s 81ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.0587 - val_accuracy: 0.9820\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 38s 80ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0611 - val_accuracy: 0.9823\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 38s 80ms/step - loss: 0.0073 - accuracy: 0.9974 - val_loss: 0.0681 - val_accuracy: 0.9818\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 37s 80ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0602 - val_accuracy: 0.9834\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb0e0bd2950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "gJ2n1OLnpepp",
        "outputId": "c8a9179d-5a55-4e5e-9b5b-4f1b9f18e8b4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "figure = plt.figure(figsize=(40,40))\n",
        "for i in range(10):\n",
        "    figure.add_subplot(1,10,i+1)\n",
        "    plt.imshow(X_test[i+50,:,:,0],cmap=\"gray\")\n",
        "    plt.axis(\"off\")\n",
        "    print(np.squeeze(np.argmax(model.predict(X_test[i+50].reshape(1,28,28,1)),axis=1),axis=0),end=\"\\t\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\t3\t5\t5\t6\t0\t4\t1\t9\t5\t"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2880x2880 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}