{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNn2G/XfDCYcSu9nezJRpzq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pravallika-1305/WISE_ML/blob/main/RNN_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xatJeWSHPcaY"
      },
      "source": [
        "\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMC-37umTkdK",
        "outputId": "aa8d3bd2-fb18-4efc-f7ea-31286902f595"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VGft2YnTtw7"
      },
      "source": [
        "# load ascii text and covert to lowercase\n",
        "filename = \"/content/drive/My Drive/Data/wonderland.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FswUJ32xUWsc"
      },
      "source": [
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-Se2M45UmtW",
        "outputId": "22e8b143-c16d-4819-9652-0f313dd16aac"
      },
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  164045\n",
            "Total Vocab:  63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "us4noLU-U1Zn",
        "outputId": "99392896-4f8a-40f3-a4bb-fa6a05ee45f8"
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  163945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6eG-w0_VM0Y"
      },
      "source": [
        "\n",
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Zv5bQZ5VT5J"
      },
      "source": [
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG8a1aCFWHGt"
      },
      "source": [
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDSHhYC-Vh0B",
        "outputId": "0f0bc8ff-8bc1-4aea-d9c1-e1ac36238f24"
      },
      "source": [
        "model.fit(X, y, epochs=20, batch_size=128,callbacks=callbacks_list)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1281/1281 [==============================] - 846s 661ms/step - loss: 2.9680\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.96797, saving model to weights-improvement-01-2.9680.hdf5\n",
            "Epoch 2/20\n",
            "1281/1281 [==============================] - 839s 655ms/step - loss: 2.8388\n",
            "\n",
            "Epoch 00002: loss improved from 2.96797 to 2.83878, saving model to weights-improvement-02-2.8388.hdf5\n",
            "Epoch 3/20\n",
            "1281/1281 [==============================] - 841s 656ms/step - loss: 2.7668\n",
            "\n",
            "Epoch 00003: loss improved from 2.83878 to 2.76677, saving model to weights-improvement-03-2.7668.hdf5\n",
            "Epoch 4/20\n",
            "1281/1281 [==============================] - 837s 654ms/step - loss: 2.7016\n",
            "\n",
            "Epoch 00004: loss improved from 2.76677 to 2.70156, saving model to weights-improvement-04-2.7016.hdf5\n",
            "Epoch 5/20\n",
            "1281/1281 [==============================] - 838s 654ms/step - loss: 2.6468\n",
            "\n",
            "Epoch 00005: loss improved from 2.70156 to 2.64677, saving model to weights-improvement-05-2.6468.hdf5\n",
            "Epoch 6/20\n",
            "1281/1281 [==============================] - 835s 652ms/step - loss: 2.5917\n",
            "\n",
            "Epoch 00006: loss improved from 2.64677 to 2.59175, saving model to weights-improvement-06-2.5917.hdf5\n",
            "Epoch 7/20\n",
            "1281/1281 [==============================] - 838s 654ms/step - loss: 2.5425\n",
            "\n",
            "Epoch 00007: loss improved from 2.59175 to 2.54251, saving model to weights-improvement-07-2.5425.hdf5\n",
            "Epoch 8/20\n",
            "1281/1281 [==============================] - 839s 655ms/step - loss: 2.4960\n",
            "\n",
            "Epoch 00008: loss improved from 2.54251 to 2.49597, saving model to weights-improvement-08-2.4960.hdf5\n",
            "Epoch 9/20\n",
            "1281/1281 [==============================] - 839s 655ms/step - loss: 2.4568\n",
            "\n",
            "Epoch 00009: loss improved from 2.49597 to 2.45680, saving model to weights-improvement-09-2.4568.hdf5\n",
            "Epoch 10/20\n",
            "1281/1281 [==============================] - 839s 655ms/step - loss: 2.4171\n",
            "\n",
            "Epoch 00010: loss improved from 2.45680 to 2.41705, saving model to weights-improvement-10-2.4171.hdf5\n",
            "Epoch 11/20\n",
            "1281/1281 [==============================] - 836s 652ms/step - loss: 2.3784\n",
            "\n",
            "Epoch 00011: loss improved from 2.41705 to 2.37841, saving model to weights-improvement-11-2.3784.hdf5\n",
            "Epoch 12/20\n",
            "1281/1281 [==============================] - 843s 658ms/step - loss: 2.3429\n",
            "\n",
            "Epoch 00012: loss improved from 2.37841 to 2.34294, saving model to weights-improvement-12-2.3429.hdf5\n",
            "Epoch 13/20\n",
            "1281/1281 [==============================] - 842s 657ms/step - loss: 2.3094\n",
            "\n",
            "Epoch 00013: loss improved from 2.34294 to 2.30937, saving model to weights-improvement-13-2.3094.hdf5\n",
            "Epoch 14/20\n",
            "1281/1281 [==============================] - 850s 663ms/step - loss: 2.2831\n",
            "\n",
            "Epoch 00014: loss improved from 2.30937 to 2.28307, saving model to weights-improvement-14-2.2831.hdf5\n",
            "Epoch 15/20\n",
            "1281/1281 [==============================] - 854s 667ms/step - loss: 2.2492\n",
            "\n",
            "Epoch 00015: loss improved from 2.28307 to 2.24924, saving model to weights-improvement-15-2.2492.hdf5\n",
            "Epoch 16/20\n",
            "1281/1281 [==============================] - 848s 662ms/step - loss: 2.2239\n",
            "\n",
            "Epoch 00016: loss improved from 2.24924 to 2.22390, saving model to weights-improvement-16-2.2239.hdf5\n",
            "Epoch 17/20\n",
            "1281/1281 [==============================] - 845s 659ms/step - loss: 2.1971\n",
            "\n",
            "Epoch 00017: loss improved from 2.22390 to 2.19709, saving model to weights-improvement-17-2.1971.hdf5\n",
            "Epoch 18/20\n",
            "1281/1281 [==============================] - 840s 656ms/step - loss: 2.1736\n",
            "\n",
            "Epoch 00018: loss improved from 2.19709 to 2.17364, saving model to weights-improvement-18-2.1736.hdf5\n",
            "Epoch 19/20\n",
            "1281/1281 [==============================] - 849s 663ms/step - loss: 2.1488\n",
            "\n",
            "Epoch 00019: loss improved from 2.17364 to 2.14878, saving model to weights-improvement-19-2.1488.hdf5\n",
            "Epoch 20/20\n",
            "1281/1281 [==============================] - 867s 677ms/step - loss: 2.1273\n",
            "\n",
            "Epoch 00020: loss improved from 2.14878 to 2.12728, saving model to weights-improvement-20-2.1273.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1b64b0c190>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGcHhsQBWB_k",
        "outputId": "40b0f894-882f-4dab-8b52-1c29f37f4763"
      },
      "source": [
        "# pick a random seed\n",
        "import sys\n",
        "\n",
        "\n",
        "\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\" _ mind what you’re doing!” cried alice, jumping up and down\n",
            "in an agony of terror. “oh, there goes h \"\n",
            "ate an at the waite to tee the oi the saae to tee sie of the saaei, and the waited to the toeee an ih shu so the tabde hf i soede to tee the was oo the tooe. “he ioer tht toen i taad to the kante oo toe toe oe the saaei of the sooe. \n",
            "“h woul io ”hu ”hul to tou then you mane,” said the daterpillar.\n",
            "\n",
            "“whll, i shanl you dane to tee woine io the woudd ”ou ”hul to tou,” \n",
            "“i wonl you dan ”ou dane wo the woide of the soie,” saed the gatter. “ih sou de io whe hors of the goor ”f\n",
            "thee io the soees ”ou thu      bn af iod tee th the wait oo to the wai oo the tooe. \n",
            "“h whnl toe ”ou donw ”hu      bn of the sooe tf the woile.”\n",
            "\n",
            "“i wonl you can ”ou dane wo the coolo ” saed the daterpillar.\n",
            "\n",
            "“ie cours an ier ”as _ lirt ei a larter ” said alice. “ih aod toe karte oo tee toiee of the saae to tee siee ”ou  an you dan tou donw ”hut toe oo toen i whol tou ”hu      bn at aad to de      ani the woide oo toe the wai oo the taate. and the wart oo io the douro  she kad goen tai the wait on in the court, and the\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}